# 🤖 DixonGPT

DixonGPT is a **web-based chat AI** powered by a **Mini Llama model**, optimized for **minimal resource usage**.  

---

## 🧩 Overview
This project deploys the AI model inside a **Docker container** running on **AWS services**, providing an efficient and scalable infrastructure.

---

## ☁️ AWS Architecture

| Service | Purpose |
|----------|----------|
| **🪣 Amazon S3** | Stores the trained model files. |
| **🐳 Amazon ECR** | Manages and hosts the Docker image. |
| **💻 Amazon EC2** | Runs the Docker container and serves the chat application. |

---

## ⚙️ Features
- Lightweight Llama-based AI model  
- Deployed with Docker for portability  
- Integrated with AWS for scalability and reliability  

---

## 🚀 Quick Start (coming soon)
Instructions on how to build, deploy, and run DixonGPT will be added here.

---

## 📄 License
This project is licensed under the [MIT License](LICENSE).

---
🧠 *Developed by Jafet Dixon*

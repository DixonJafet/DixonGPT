# 🤖 DixonGPT

DixonGPT is a **web-based chat AI** powered by a **Mini Llama model**, optimized for **minimal resource usage**.  
The **frontend website** is built with **Angular**, providing a fast and responsive user experience.

---

## 🧩 Overview
This project deploys the AI model inside a **Docker container** running on **AWS services**, providing an efficient and scalable infrastructure.

---

## ☁️ AWS Architecture

| Service | Purpose |
|----------|----------|
| **🪣 Amazon S3** | Stores the trained model files. |
| **🐳 Amazon ECR** | Manages and hosts the Docker image. |
| **💻 Amazon EC2** | Runs the Docker container and serves the chat application. |

---

## 🧠 Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | ⚡ Angular |
| **Backend** | 🐍 Python (Mini Llama model) |
| **Containerization** | 🐳 Docker |
| **Proxy** | NGINX  |
| **Infrastructure** | ☁️ AWS (S3, ECR, EC2) |

---

## 🚀 Quick Start (coming soon)
[Go to the WebSite](https://dixon-gpt.vercel.app/).

---

## 📄 License
This project is licensed under the [MIT License](LICENSE).

---

🧠 *Developed by Jafet Dixon*

